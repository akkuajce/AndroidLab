
Experiment No.: 1

Aim: Write a program to perform matrix operations. Use Numpy as the python library and perform the operations using built in functions in Numpy.

CO1: Use different python packages to perform numerical calculations, statistical computations and data visualization

Procedure:
import numpy as np
def input_matrix(matrix_name):
   rows = int(input(f"Enter the no of rows of {matrix_name}: "))
   cols = int(input(f"Enter the no of columns of {matrix_name}: "))
   matrix=[]
   print("Enter the elements:")
   for i in range(rows):
       rows=[]
       for j in range(cols):
           element=int(input(f"Enter the element at row {i+1},column {j+1}:"))
           rows.append(element)
       matrix.append(rows)
   return np.array(matrix)
matrix1 = input_matrix("matrix1")
matrix2 = input_matrix("matrix2")
sum = np.add(matrix1, matrix2)
print("Addition=", sum)
diff = np.subtract(matrix1, matrix2)
print("Subtraction=", diff)
prod = np.multiply(matrix1, matrix2)
print("Multiplication=", prod)
div = np.divide(matrix1, matrix2)
print("Division=", div)
transp = np.transpose(matrix1)
print("Transpose=", transp)
dot = np.dot(matrix1, matrix2)
print("Dot product=", dot)






Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO1 has been attained.














Experiment No.: 2

Aim: Program to perform single value decomposition(SVD) using python Numpy.

CO1: Use different python packages to perform numerical calculations, statistical computations and data visualization

Procedure:
import numpy as np
matrix = np.array([[5, 6, 4],
                  [2, 5, 6],
                  [3, 5, 6]])
U, S, VT = np.linalg.svd(matrix)
print("Matrix U: ")
print(U)
print("Matrix S: ")
print(np.diag(S))
print("Matrix VT: ")
print(VT)
recnstrct = np.dot(U,np.dot(np.diag(S),VT))
print("Old Matrix: ")
print(recnstrct)


Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO1 has been attained.



Experiment No.: 3

Aim: Program to perform data visualisation using the python library matplotlib.
CO1: Use different python packages to perform numerical calculations, statistical computations and data visualization.

Procedure:
import matplotlib.pyplot as plt
categories=["a","b","c","d"]
values=[1,2,3,4]
plt.bar(categories,values,color='skyblue')
plt.xlabel(categories)
plt.ylabel(values)
plt.title("barchart")
plt.show()

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO1 has been attained.



Experiment No.: 4

Aim: Program to implement k-NN classification using any standard dataset available in the public domain and find the accuracy of the algorithm. (Iris Dataset).

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
iris=load_iris()
x=iris.data
y=iris.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
knn=KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)
print(knn.predict(x_test))
V=knn.predict(x_test)
result=accuracy_score(y_test,V)
print("Accuracy= ",result)


Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.





Experiment No.: 5

Aim: Program to implement k-NN classification using any standard dataset available in the public domain and find the accuracy of the algorithm. (Load Digits)

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
digits=load_digits()
x=digits.data
y=digits.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
knn=KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)
print((knn.predict(x_test)))
P=knn.predict(x_test)
R=accuracy_score(y_test,P)
print("Accuracy= ",R)


Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.


Experiment No.: 6

Aim: Program to implement Naïve Bayes Algorithm using any standard dataset available in the public domain and find the accuracy of the algorithm.

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
iris=load_iris()
x=iris.data
y=iris.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
clf=GaussianNB()
clf.fit(x_train,y_train)
print(clf.predict(x_test))
V=clf.predict(x_test)
result=accuracy_score(y_test,V)
print("Accuracy= ",result)

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.




Experiment No.: 7

Aim: Program to implement Naïve Bayes Algorithm using any standard dataset available in the public domain and find the accuracy of the algorithm.

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report
bc=load_breast_cancer()
x=bc.data
y=bc.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
gnb=GaussianNB()
gnb.fit(x_train,y_train)
print(gnb.predict(x_test))
G=gnb.predict(x_test)
result=accuracy_score(y_test,G)
print("Accuracy= ",result)
cr=classification_report(y_test,G)
print("/n Classification Report: ",cr)

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.


Experiment No.: 8

Aim: Given a one dimensional data represented with Numpy array. Write a program to calculate slope and intercept.

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np
x_value = np.array([64,75,68,73,78,82,76,85,71,88]).reshape(-1,1)
y_value = np.array([17,27,15,24,39,44,30,48,19,47])
model=LinearRegression()
model.fit(x_value,y_value)
slope=model.coef_[0]
intercept=model.intercept_
print(f"Slope: {slope}")
print(f"Intercept: {intercept}")

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.









Experiment No.: 9

Aim: Program to implement Simple Linear Regression using any standard dataset available in public domain and find the R2 score.

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
data=pd.read_csv('Salary_Data.csv')
x=data['YearsExperience'].values.reshape(-1,1)
y=data['Salary'].values
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
LR=LinearRegression()
LR.fit(x_train,y_train)
D=LR.predict(x_test)
r2 = r2_score(y_test, D)
print("R2 Score: ", r2)
plt.scatter(x_test,y_test,color='black',label='Data Points')
plt.plot(x_test,D,color='blue', linewidth=3,label='Regression Line')
plt.xlabel='YearsExperience'
plt.ylabel='Salary'
plt.legend()
plt.show()











Output Screenshot



Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.
















Experiment No.: 10

Aim: Program to implement Multiple Linear Regression using any standard dataset available in public domain.

CO2: Use different packages and frameworks to implement regression and classification algorithms.

Procedure:
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
california_housing=fetch_california_housing()
df=pd.DataFrame(data=california_housing.data,columns=california_housing.feature_names)
df['Target']=california_housing.target
x=df.drop('Target',axis=1)
y=df['Target']
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
model = LinearRegression()
model.fit(x_train, y_train)
predictions = model.predict(x_test)
mse = mean_squared_error(y_test, predictions)
print(f"Mean Squared Error: {mse}")

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO2 has been attained.








Experiment No.: 11

Aim: Program to implement decision trees using any standard dataset available in the public domain and find the accuracy of the algorithm.

CO3: Use different packages and frameworks to implement text classification using SVM and clustering using k-means.
Procedure:
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.metrics import accuracy_score,classification_report
from matplotlib import pyplot as plt
iris=load_iris()
x=iris.data
y=iris.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
dt=DecisionTreeClassifier(max_depth=3)
dt.fit(x_train,y_train)
print(dt.predict(x_test))
D=dt.predict(x_test)
result=accuracy_score(y_test,D)
print("Accuracy= ",result)
cr=classification_report(y_test,D)
print("Classification Report: ",cr)
plt.figure(figsize=(15,20))
plot_tree(dt,filled=True,feature_names=iris.feature_names,class_names=iris.target_names)
plt.title("Decission Tree")
plt.show()

Output Screenshot








Result: The program was executed successfully and the output was obtained. Thus, CO3 has been attained.
















Experiment No.: 12

Aim: Program to implement decision trees using any standard dataset available in the public domain and find the accuracy of the algorithm.

CO3: Use different packages and frameworks to implement text classification using SVM and clustering using k-means 

Procedure:
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.metrics import accuracy_score,classification_report
from matplotlib import pyplot as plt
bc=load_breast_cancer()
x=bc.data
y=bc.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
dt=DecisionTreeClassifier(max_depth=2)
dt.fit(x_train,y_train)
print(dt.predict(x_test))
D=dt.predict(x_test)
result=accuracy_score(y_test,D)
print("Accuracy= ",result)
cr=classification_report(y_test,D)
print("Classification Report: ",cr)
plt.figure(figsize=(15,10))
plot_tree(dt,filled=True,feature_names=bc.feature_names,class_names=bc.target_names)
plt.title("Decission Tree")
plt.show()

Output Screenshot








Result: The program was executed successfully and the output was obtained. Thus, CO3 has been attained.

















Experiment No.: 13

Aim: Program to implement k-means clustering technique using any standard dataset available in the public domain 

CO3: Use different packages and frameworks to implement text classification using SVM and clustering using k-means

Procedure:
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
iris = load_iris()
x = iris.data
y = iris.target
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(x)
cluster_labels = kmeans.labels_
print(cluster_labels)
centroids = kmeans.cluster_centers_
print(centroids)
plt.scatter(x[:, 0], x[:, 1], c=cluster_labels, cmap='viridis', marker='o', edgecolors='black')
plt.scatter(centroids[:, 0], centroids[:, 1], marker="*", s=200, c='red', label='Centroids')
plt.xlabel(iris.feature_names[0])
plt.ylabel(iris.feature_names[1])
plt.title('KMeans Cluster of Iris Dataset')
plt.legend()
plt.show()



Output Screenshot




Result: The program was executed successfully and the output was obtained. Thus, CO3 has been attained.


















Experiment No.: 14

Aim: Program to implement k-means clustering technique using any standard dataset available in the public domain 

CO3: Use different packages and frameworks to implement text classification using SVM and clustering using k-means

Procedure:
from sklearn.datasets import load_breast_cancer
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
bc = load_breast_cancer()
x = bc.data
y = bc.target
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(x)
cluster_labels = kmeans.labels_
print(cluster_labels)
centroids = kmeans.cluster_centers_
print(centroids)
plt.scatter(x[:, 0], x[:, 1], c=cluster_labels, cmap='viridis', marker='o', edgecolors='black')
plt.scatter(centroids[:, 0], centroids[:, 1], marker="*", s=200, c='red', label='Centroids')
plt.xlabel(bc.feature_names[0])
plt.ylabel(bc.feature_names[1])
plt.title('KMeans Cluster of Breast Cancer Dataset')
plt.legend()
plt.show()












Output Screenshot




Result: The program was executed successfully and the output was obtained. Thus, CO3 has been attained.

















Experiment No.: 15

Aim: Program to implement text classification using support vector machine.

CO3: Use different packages and frameworks to implement text classification using SVM and clustering using k-means

Procedure:
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score ,classification_report
categories=['alt.atheism','soc.religion.christian','comp.graphics','sci.med']
twenty_train=fetch_20newsgroups(subset='train',categories=categories,shuffle=True,random_state=42)
vectorizer=TfidfVectorizer()
X_train_tfidf=vectorizer.fit_transform(twenty_train.data)
y_train = twenty_train.target
x_train,x_test,y_train,y_test=train_test_split(X_train_tfidf,y_train,test_size=0.2,random_state=42)
svm_classifier=SVC(kernel='linear',random_state=42)
svm_classifier.fit(x_train,y_train)
predictions=svm_classifier.predict(x_test)
accuracy=accuracy_score(y_test,predictions)
classification=classification_report(y_test,predictions,target_names=twenty_train.target_names)
print("Accuracy",accuracy)
print("classification_report:",classification)
new_data=["I have a question about computer graphics","This is a medical related topic"]
x_new_tfidf=vectorizer.transform(new_data)
new_predictions=svm_classifier.predict(x_new_tfidf)
for i,text in enumerate(new_data):
 predicted_category=twenty_train.target_names[new_predictions[i]]
 print("Predicted Cate",predicted_category)








Output Screenshot



Result: The program was executed successfully and the output was obtained. Thus, CO3 has been attained.


























Experiment No.: 16

Aim: Program on artificial neural network to classify images from any standard dataset in the public domain using Keras framework.
CO4: Implement convolutional neural network algorithm using Keras framework.

Procedure:
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
# Load the MNIST dataset
(X_train, y_train), (X_test, y_test) =mnist.load_data()
# Normalize pixel values to be between 0 and 1
X_train = X_train / 255.0
X_test = X_test / 255.0
# Flatten the images (convert 28x28 images to 1D vectors)
X_train = X_train.reshape(-1, 28 * 28)
print(X_train)
X_test = X_test.reshape(-1, 28 * 28)
print(X_train)
# One-hot encode the target labels
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print(y_test)
# Create a simple feedforward neural network model
model=Sequential([
Dense(128, activation='relu', input_shape=(28 * 28,)),
Dense(68, activation='relu'),
Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train,y_train, epochs=5 , batch_size=32, validation_split=0.2)
loss, accuracy= model.evaluate(X_test,y_test)
print(accuracy)







Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO4 has been attained.






























Experiment No.: 17

Aim: Program to implement a simple web crawler using requests library.
CO5: Implement programs for web data mining and natural language processing using NLTK.

Procedure:
import requests
def simple_scraper(url):
   response=requests.get(url)
   if response.status_code==200:
       print("Content:")
       print(response.text)
   else:
       print("Failed to fetch the page. Status code:", response.status_code)
url_to_scrap="https://ajce.in"
simple_scraper(url_to_scrap)

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO5 has been attained.








Experiment No.: 18

Aim: Program to implement a simple web crawler and parse the content using BeautifulSoup.
CO5: Implement programs for web data mining and natural language processing using NLTK.

Procedure:
import requests
from bs4 import BeautifulSoup
def simple_scraper(url):
   response=requests.get(url)
   if response.status_code==200:
       soup=BeautifulSoup(response.content, 'html.parser')
       print("Title:",soup.title.string)
       print("Content:")
       print(soup.get_text())
   else:
       print("Failed to fetch the page. Status code:", response.status_code)
url_to_scrap="https://ajce.in"
simple_scraper(url_to_scrap)

Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO5 has been attained.






Experiment No.: 19

Aim: Implement problems on natural language processing - Part of Speech tagging, N-gram & smoothening and Chunking using NLTK.
CO5: Implement programs for web data mining and natural language processing using NLTK.

Procedure:
import nltk
nltk.download('brown')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.corpus import brown
from nltk.chunk import RegexpParser
sentence = "The quick brown fox jumps over the lazy dog"
tokens = word_tokenize(sentence)
print(tokens)
pos_tags = nltk.pos_tag(tokens)
print("Part-of-Speech Tagging: ")
print(pos_tags)
text = brown.words(categories='news')[:1000]
bigrams = list(ngrams(text, 2))
freq_dist = nltk.FreqDist(bigrams)
print("\n N-gram Analysis (Bigrams with Smoothing): ")
for bigram in bigrams:
print(f"{bigram}: {freq_dist[bigram]}")
tagged_sentence = nltk.pos_tag(word_tokenize("The quick brown fox jumps over the lazy dog"))
grammar = r"NP: {<DT>?<JJ>*<NN>}"
cp = RegexpParser(grammar)
result = cp.parse(tagged_sentence)
print("\n Chunking with Regular Expressions and POS tags: ")
print(result)








Output Screenshot


Result: The program was executed successfully and the output was obtained. Thus, CO5 has been attained.


20MCA241 – Data Science Lab                                                                       Dept. of Computer Applications



Amal Jyothi College of Engineering, Kanjirappally	                                                                                             1


